---
title: "data.table interviews!"
author: "Anirban Chetia"
date: "2024-02-09"
categories: [interviews]
image: ""
---

## Motivations in contributing

Forms of bringing in people are mostly subjected to one’s interests, which come in various forms:

- Using the software for not just work but for a personal project of interest where they derive usefulness from functions exported by data.table.

- Trying to be a part of the data.table community, wherein the feeling of being a part of something big and crucial tends to be in play here. Making connections in the open-source community also tends to be an attraction.

- For work reasons, wherein their core goal is to help maintain their own software/package (downstream dependencies) by contributing back.

- For visibility or for employment where data.table is a required/preferred tool of trade, and adds to their CV.

- Making one a better programmer. This comes to be not just by contributing directly, but also by learning from others’ contributions.

- Financial gain.


## Reasons for not using/adopting

- Low rationale to switch to data.table when dealing with small datasets as notable efficiency (in comparison to other R packages that achieve the same functionality) is mostly seen when the data being dealt with is considerably large, or the operations performed on them scale well to see a visible difference.

- On the flipside, there are rare cases where people found data.table to be not scalable enough (and instead used DuckDB) for their current datasets, which are increasingly larger than memory (to make operations work on-disk would be something to look out for and implement in the future). An intermediate solution for them here would be to have a syntax translator tool that would translate data.table syntax to SQL queries (similar to what `dbplyr` is for `dplyr` commands) as they prefer the data.table way to write code and only require things to be more scalable.
 
- Not enough resources online to learn data.table in an easy yet detailed manner. This comes in stark contrast to abundant resources available for topics such as `data.frame` and `dplyr` for instance.

- Lack of an integration with `tidyverse`.

- Not working with a group of collaborators/coworkers who primarily use data.table.

- For a handful, the syntax does not come to be natural although they potentially benefit from the speed. They would stick to tidyverse or base R in terms of being easier to use, unless they are running big computations where time is key. 

- Some feel that data.table requires a certain level of understanding and experience in R prior to using it. They believe that it isn't easy for newbies to adapt reasonably quickly, with regards to their own experiences in learning it. For reasons discussed above again, people with beginner-level experience in R or not enough reason to have code be the most efficient tend to stick with easier-to-use packages and functions, which is especially common in entry-level data science courses.


## Barriers in contributing

- Not being a heavy user of the package. To both be reliant on active maintenance of the currently offered functionality and to see the value of time invested in contributing, one has to use data.table often enough - something that not everyone does. (the pressing need to rely on the tool needs to be existent for some to contribute i.e.)

- Time in between submission and merging of a PR being rather long. This resonated with a few who contributed in the past, and some were just concerned for the ones who have or are contributing, as they may opt out of future contributions if their pull requests are left hanging for a long time. Given that it takes time to be thorough with changes introduced in pull requests (PRs), there is room for understanding if they are not merged timely or fast enough since in the long run, unintended consequences are always a possibility after the foreign code has been integrated (might break stuff and make it harder to debug later on). People do feel that taking the quick and easy route in merging PRs (especially big ones) can be challenging or that contributors and reviewing volunteers have limited time, however, they also think it can be faster (especially if more people are involved) and massive delays (ranging from several weeks to months) can be avoided. (especially since people would also lose context regarding their contributions and would need to revisit the discussion as a whole)

- Some users find the language used to bring in people to be close-ended. They would be inclined and interested to contribute if the available reading material (such as the FAQ and Readme) is more inviting and friendly.

- Lack of professional motivation and brevity. Some users are tightly occupied with work and do not have the time to contribute to open-source projects, let alone data.table (would be an addition to their list of competing priorities). For the few who do, they choose not to contribute either due to the lack of incentive, or due to the lack of motivation, primarily fueled by them thinking their contributions would not be satisfactory in comparison to what they would usually contribute to for the products they develop for their job.
 
- The feeling of not having adequate knowledge to make meaningful contributions. For a handful, the codebase is overwhelming, and/or they are new to GitHub itself and not sure where to start digging, and/or they are not used to working with that type or level of code in R.
  
- Lack of C programming knowledge. Although at the surface there is R, the core still has C and thus a fair proportion of the people interviewed mentioned that their inexperience with the language is one reason that holds them back from making contributions (especially ones that involve diving a bit deeper).

- It is not something they use in their current toolchain. This specifically applies to the people who were former contributors or users - For them data.table is a technology they used in the past for their former work/interests, and not something they require to or would consider using for their job at present. For some, they might need an entire career switch to even use R as well!

- Diversity. Language (English is not their primary language, and a fair amount of jargons exist while going through the vignettes) tends to be a barrier (the inclusion of more people through translations would be something to look forward to), apart from the potential narrowing of contributors who are not as accustomed to R or optimized programming principles. A broader approach might be required for newcomers to open issues and pull requests. Additionally, people tend to adopt the ‘contributor mode’ when sought upon - simple things like making it explicit on the GitHub repository that contributors are needed can pull them towards deciding to push a change.


## Areas of Improvement

### Technical

- An R core member dealing gingerly pointed out that after several years of abundant reports of installation problems on MacOS, data.table still shows as being unable to detect OpenMP support and use multiple threads on the platform (while the same is not prevalent on Windows or Linux), even after including OpenMP run-time in CRAN R releases specifically for data.table. I noticed the same issue too (and it has been there for a while as it appears, as I first [encountered](https://github.com/Anirban166/Mac-Issues/issues/2) it more than two years ago) on OS X being prevalent till date.

- People miss `fread` being able to read fixed-width files, although there is `iotools` now.

- Additional functionality for working with spatial geometries and mixed-model packages (such as `glmmTMB` and `lme4`).

- Some people found using the Walrus operator to be weird, especially given that not every data.table operation requires that. They don't like keeping in mind the names of columns (they tend to move towards the set function for explicitly assigning) as well. The in-place assignment using `:=` is acceptable as they feel, but they would ideally want to be able to do `DT$x <- y` meaning `DT[, x := y]`.

- `dataset[get("categoricalColumn")]` could be optimized further.

- Efficient visualization methods can be introduced, if applicable or intuitive.

- A few people find the syntax of `dcast` and `melt` to be confusing, and often end up making mistakes since those reshaping operations complement each other (long to wide and vice versa respectively) or are the reverse. Probably not best to change this given it would break things and is just something to be learned over time, but more examples might help.

- More often a mild inconvenience than a common source of error, but to a few, the masking of other packages is something they do not like.

### Non-technical

- Documentation tends to be lacking, i.e. not enough well-documented data.table resources or online materials (blogs/articles, videos) exist. Even experienced developers feel that it isn't entirely straightforward to find out how to do more complex things, so more extensive documentation and examples would be great, if not a necessity. Making existing documentation more lucid and navigable, while less aggressive for certain phrases out of old-school culture, is another point mentioned by a few. Things that read as friendly and expressive while maintaining details are a go-to.

- More involvement is required on Stack Exchange or QA-oriented platforms that programmers and alike frequent. People mentioned that when they are looking for answers on Stack Overflow for questions that they come across in R, they find that `data.table`-based answers are lacking compared to `dplyr`.

- Most educational institutions do not resort to having data.table as part of their curriculum in R-based courses. While the coursework tends to be easier for newcomers, having more resources accessible can help people learn the more optimized version right from scratch and avoid learning it in the long run (almost all of the interviewees had to explore `data.table` on their own!) when efficiency or just the concise way of writing things is found to be better for some. Thus, it might help if instructors can start incorporating lessons using the package.
