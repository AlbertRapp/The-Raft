{
  "hash": "7b423041c3f353cb72f26a8d623a822e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: 'Performance Comparison: `data.table` in R and `pandas` in Python'\nauthor: \"Doris Amoakohene\"\ndate: \"2024-10-10\"\ndraft: true\nexecute:\n  eval: false\n---\n\n\n\n\nR and Python are two programming languages that have gained immense popularity among data scientists, statisticians, and researchers. In this blog, we will explore two widely used libraries, `data.table` in R and `pandas` in Python, both of which excel in data manipulation and provide versatile functionalities for working with data, focusing on their capabilities for reading, writing, and reshaping data. We will also explain how to graphically demonstrate the time taken by each operation. We will use the `atime` R package to compare and visualize the asymptotic performance (time and memory usage) of the different functions mentioned above. By comparing the asymptotic performance of these packages in these programming languages, we aim to provide insights and help data scientists make informed choices when it comes to data manipulation and analysis.\n\n## Performance testing with `atime`\n\nThe `atime::atime()` function requires the following arguments: \n\n* `N`: A sequence of parameters that control dataset sizes. Peformance tests will measure time/memory usage across the different data sizes, as measured by values of `N`. \n\n* `setup`: A code expression that will be run for each value in `N` to create data of various sizes.\n\n* `expr`: A code expression that will be evaluated for each value in `N`, after data creation, and tested for computational performance.\n\n* `seconds.limit` (optional): A cutoff time; if an expression is slower than this limit for any data size, then no larger data sizes will be measured.\n\n## Interfacing Python and R with `reticulate`\n\nThis analysis will employ the `reticulate` package in R, which facilitates interoperability between Python and R by providing a robust set of tools for seamless integration. Leveraging this package enables the efficient exchange of data and functionality between both languages, allowing for a more expansive approach to the analysis. The package includes facilities for:\n\n1.  Calling Python from R, including raw code or sourcing Python scripts and modules.\n\n2.  Translation between R and Python objects; for example, between R and pandas data frames, or between R matrices and NumPy arrays.\n\n3.  Flexible binding to different versions of Python including virtual environments and Conda environments.\n\nThe `reticulate` translation incurs overhead depending on Python code complexity and frequency of R-Python switches. This overhead is typically constant for small scripts, but increases with larger/complex code. The code uses reticulate to benchmark writing a dataframe to CSV using R's data.table and Python's pandas, with key overhead factors being Python environment initialization and data transfer between R and Python. Data transfer overhead is relatively constant due to small dataframe size and minimal changes in dataframe size during processing.\n\n<!-- que? download the image below -->\n\nhttps://github.com/DorisAmoakohene/Slides-and-Blogs/blob/main/Screenshot%202024-06-26%20150315.png\n\n## Example 1: Writing a CSV File with data.table::fwrite() and pandas::to_csv()\n\n### Setup\n\nTo reproduce this analysis, you will need the packages loaded in the code chunks shown below, as well as the code to setup a virtual environment using your choice of local Python install.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nlibrary(reshape2)\nlibrary(atime)\nlibrary(ggplot2)\nlibrary(reticulate)\n#use_python(\"C:/Users/amoak/AppData/Local/Programs/Python/Python312/python.exe\") #If you want to reproduce, please change to the path of python on your computer.\nvirtualenv_create(\"fm-proj\")\nuse_virtualenv(\"fm-proj\", required = F)\n```\n:::\n\n\n\n\n<!-- is this needed? -->\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfile_path = 'data.csv'\n```\n:::\n\n\n\n\n\n## fwrite: fast CSV writer\n\nData.table provides the fwrite() function for writing data to a file while Pandas offers the to_csv() function for writing data to a CSV file.\n\n## Comparison code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite.colors <- c(\n  \"data.table::fwrite\" = \"#D6604D\",\n  \"pandas.to_csv \" = \"#BF812D\"\n)\nfile_path = 'data.csv'\nn.rows <- 100\nseconds.limit <- 10\natime.write.vary.cols <- atime::atime(\n  N = as.integer(10^seq(2, 10, by = 0.2)),\n  setup = {\n    set.seed(1)\n    input.vec <- rnorm(n.rows * N)\n    input.mat <- matrix(input.vec, n.rows, N)\n    input.df <- data.frame(input.mat) \n    pd <- import(\"pandas\")\n    input_df_pd <- r_to_py(input.df)\n  },\n  seconds.limit = seconds.limit,\n  \"data.table::fwrite\" = {\n    data.table::fwrite(input.df, tempfile(), showProgress = FALSE)\n  },\n  \"pandas.to_csv\" = {\n    input_df_pd$to_csv(file_path, index = FALSE)\n  }\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrefs.write.vary.cols <- atime::references_best(atime.write.vary.cols)\n```\n:::\n\n\n\n\nThe predict() function is used to generate predictions based on the atime::reference_best() dataset. The resulting plot illustrates the data size, N, that can be processed within a specific time or memory limit.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred.write.vary.cols <- predict(refs.write.vary.cols)\nplot(pred.write.vary.cols)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngg.write.dt.pd <- plot(pred.write.vary.cols) +\n  theme(text = element_text(size = 15)) +\n  ggtitle(sprintf(\"Write real numbers to CSV, with pandas in Python \\nand data.table in R, %d x N\", n.rows)) +\n  scale_x_log10(\"N = number of columns to write\") +\n  scale_y_log10(\"Computation time (seconds)\\nmedian line, min/max band\\nover 10 timings\") +\n  facet_null() +\n  scale_fill_manual(values = write.colors) +\n  scale_color_manual(values = write.colors)\n```\n:::\n\n\n\n\n```         \nprint(gg.write.dt.pd)\n```\n\nThe plot above shows that in terms of writing data, the data.table package in R outperforms the pandas library in Python and particularly useful when dealing with large datasets.\n\n# Example 2: Reading a CSV File with data.table::fread() and pandas.read_csv\n\n## fread: fast CSV reader\n\nData.table provides the fread() function for reading data from a CSV file while Pandas offers the read_csv() function for reading data from a CSV file.\n\n## Comparison code\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nread.colors <- c(\n  \"data.table::fread\" = \"#D6604D\",\n  \"pandas.read_csv\" = \"#BF812D\"\n)\nn.rows <- 100\nseconds.limit <- 10\nfile_path = 'data.csv'\natime.read <- atime::atime(\n  N = as.integer(10^seq(2, 15, by = 0.2)),\n  setup = {\n    set.seed(1)\n    input.vec <- rnorm(n.rows*N)\n    input.mat <- matrix(input.vec, n.rows, N)\n    input.df <- data.frame(input.mat)\n    input.csv <- tempfile()\n    fwrite(input.df, \"data.csv\")\n    pd <- import(\"pandas\")\n    input_df_pd <- pd$DataFrame(input.df)\n    pd <- import(\"pandas\")\n    reticulate::py_run_string(\"import pandas as pd\")\n  },\n  seconds.limit = seconds.limit,\n  \"data.table::fread\" = {\n    data.table::fread(\"data.csv\", showProgress = FALSE) \n  },\n  \"pandas.read_csv \" = {\n    reticulate::py_run_string(\"pd.read_csv(file_path)\")  \n  }\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nrefs.read.vary.cols <- atime::references_best(atime.read)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npred.read.vary.cols <- predict(refs.read.vary.cols)\nplot(pred.read.vary.cols)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ngg.read.pd <- plot(pred.read.vary.cols)+\n  theme(text=element_text(size=15))+\n  ggtitle(sprintf(\"Read real numbers to CSV, with pandas in Python \\nand data.table in R, %d x N\", n.rows))+\n  scale_x_log10(\"N = number of columns to write\")+\n  scale_y_log10(\"Computation time (seconds)\nmedian line, min/max band\nover 10 timings\")+\n  facet_null()+\n  scale_fill_manual(values=read.colors)+\n  scale_color_manual(values=read.colors)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(gg.read.pd)\n```\n:::\n\n\n\n\nWhen it comes to reading data, data.table in R also demonstrates its superiority. It provides fast and efficient methods for importing and reading various file formats, including CSV. The fread() function in data.table is known for its speed and memory efficiency, making it an optimal choice for handling large datasets.\n\n# Example 3. Reshape performance comparison.\n\nData reshaping means changing the shape of the data, to get it into a more appropriate format, for learning/plotting/etc. Here we consider wide to long and long to wide reshape, which means we start with a wide table (many columns) and end up with a long table (fewer columns) and vice versa.\n\n## A. wide to long reshape.\n\nIn data.table, the data.table::melt() function is used to convert data from a wide format to a long format, while in Pandas, the pandas::melt() function is used to convert data from a wide format to a long format.\n\n## Comparison code\n\n## data.table::melt() is faster\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nml.colors <- c(\n  \"data.table::melt\"=\"#D6604D\",\n  \"pd.melt\" = \"#BF812D\"\n  )\nn.folds <- 10\nn.rows <- 100\nseconds.limit <- 10\nml.reshape.atime <- atime::atime(\n  N=as.integer(10^seq(2, 15, by=0.2)),\n  setup={\n    df <- data.frame(\n      id = rep(1:N, each = 2),\n      category = rep(c(\"A\", \"B\"), N),\n      value = rnorm(2 * N)\n    py_df <- reticulate::r_to_py(df)\n    pd <- import(\"pandas\")\n      )\n    },\n  seconds.limit= seconds.limit,\n  \"data.table::melt\" = {\n    data.table::melt(data.table(df), id.vars = c(\"id\",  \"category\"),variable.names=\"variable\", value.name = \"value\")\n  },\n  \"pd.melt\" = {\n    pd$melt(py_df, id_vars = c(\"id\", \"category\"), value.name = \"score\")  \n  }\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nml.reshape.refs <- atime::references_best(ml.reshape.atime)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nml.reshape.pred <- predict(ml.reshape.refs)\nplot(ml.reshape.pred)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nml.wide2long.pd <- plot(ml.reshape.pred)+\n  theme(text=element_text(size=15))+\n  ggtitle(sprintf(\"Reshaping from wide to long panda & data.table \\nover real numbers, N times\", n.folds))+\n  scale_x_log10(\"N = number of Mean,SD,Length to compute\")+\n  scale_y_log10(\"Computation time (seconds)\nmedian line, min/max band\nover 10 timings\")+\n  facet_null()+\n  scale_fill_manual(values=ml.colors)+\n  scale_color_manual(values=ml.colors)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(ml.wide2long.pd)\n```\n:::\n\n\n\n\nWhen converting data from wide to long format, as shown in the above plot, data.table's melt() function efficiently gathers multiple columns into key-value pairs, allowing for easy transformation of wide data into a longer, more structured format.\n\n## B. long to wide reshape\n\nIn data.table, the data.table::dcast() function is often used to convert data from a long format to a wide format, and in pandas, the pd\\$pivot_table() function is used to convert data from a long format to a wide format.\n\n## Comparison code\n\n## data.table::dcast() is faster\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nml.colors <- c(\n  \"data.table::dcast\" = \"#D6604D\",\n  \"pd$pivot_table\" = \"#BF812D\"\n)\nn.folds <- 10\nn.rows <- 100\nseconds.limit <- 1\nml.long2wide.atime <- atime::atime(\n  N=as.integer(10^seq(2, 7, by=0.2)),\n  setup={\n    df <- data.frame(\n      id = rep(1:N, each = 2),\n      category = rep(c(\"A\", \"B\"), N),\n      value = rnorm(2 * N)\n     py_df <- reticulate::r_to_py(df)\n     pd <- import(\"pandas\")\n      )\n    },\n  seconds.limit= seconds.limit,\n  \"data.table::dcast\" = {\n    data.table::dcast(data.table(df), id ~ category, value.var = \"value\")\n  },\n  \"pd$pivot_table\" = {\n    pd$pivot_table(py_df, values = \"value\", index = \"id\", columns = \"category\")\n  }\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nml.long2wide.refs <- atime::references_best(ml.long2wide.atime)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nml.long2wide.pred <- predict(ml.long2wide.refs)\nplot(ml.long2wide.pred)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nml.long2wide <- plot(ml.long2wide.pred)+\n  theme(text=element_text(size=15))+\n  ggtitle(sprintf(\"Reshaping from long to wide over \\nreal numbers, N times\", n.folds))+\n  scale_x_log10(\"N = number of Mean,SD,Length to compute\")+\n  scale_y_log10(\"Computation time (seconds)\nmedian line, min/max band\nover 10 timings\")+\n  facet_null()+\n  scale_fill_manual(values=ml.colors)+\n  scale_color_manual(values=ml.colors)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(ml.long2wide)\n```\n:::\n\n\n\n\nOn the other hand, when transforming data from long to wide format, data.table's dcast() function proves to be more efficient.\n\nAlthough data.table has advantages in terms of writing, reading and rehaping, pandas library in Python still provides a solid framework for data manipulation as seen in the plot.\n\n# Conclusions\n\nIn conclusion, we have shown how to use atime to compare asymptotic time of the two packages. Both Pandas and data.table are powerful libraries for data manipulation in Python and R respectively. Pandas offers a comprehensive set of functions and a user-friendly interface, making it suitable for a wide range of data analysis tasks. On the other hand, Data.table excels in terms of performance and memory efficiency, making it an excellent choice for handling large datasets and complex operations.\n\nThe choice between the two libraries ultimately depends on the specific requirements of your data manipulation tasks. It is recommended to consider the size of the dataset, the complexity of the operations, and personal preferences when making a decision.\n\n# References:\n\nMy code was copied and modified from the code links below:\n\n[Reticulate package](https://rstudio.github.io/reticulate/)\n\n[Reticulate cheat sheet](https://github.com/rstudio/cheatsheets/blob/main/reticulate.pdf)\n\n[Reshape performance comparison](https://tdhock.github.io/blog/2024/reshape-performance/)\n\n[compare-read-write](https://tdhock.github.io/blog/2023/compare-read-write/)\n\n[data.table asymptotic timings](https://tdhock.github.io/blog/2023/dt-atime-figures/)\n\n[atime package](https://github.com/tdhock/atime)\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}