{
  "hash": "e2d1e593d2cef0bf94470f0a564b6450",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Seal of Approval: collapse\"\nauthor: \"Sebastian Krantz\"\ndate: \"Sept 21, 2024\"\ncategories: [seal of approval, partner package]\nimage: \"hex_approved.png\"\ndraft: false\n---\n\n\n## [`collapse`](https://github.com/SebKrantz/collapse)\n\n*Author(s):* Sebastian Krantz\n\n*Maintainer:* Sebastian Krantz (sebastian.krantz\\@graduateinstitute.ch)\n\n![collapse hex sticker](hex.png)\n\n`collapse` is a large C/C++-based infrastructure package facilitating complex statistical computing, data transformation, and exploration tasks in R - at outstanding levels of performance and memory efficiency. It also implements a class-agnostic approach to R programming supporting vector, matrix and data frame-like objects (includings *xts*, *tibble*, ***data.table***, and *sf*). It has a stable API, depends on *Rcpp*, and supports R versions \\>= 3.4.0.\n\n## Relationship with `data.table`\n\nAt the C-level, `collapse` took much inspiration from `data.table`, and leverages some of its core algorithms like radixsort, while adding significant [statistical functionality](https://sebkrantz.github.io/collapse/reference/collapse-documentation.html) and [new algorithms](https://sebkrantz.github.io/collapse/reference/fast-grouping-ordering.html) within a [class-agnostic programming framework](https://sebkrantz.github.io/collapse/articles/collapse_object_handling.html) that seamslessly supports `data.table`. Notably, [`collapse::qDT()`](https://sebkrantz.github.io/collapse/reference/quick-conversion.html) is a highly efficient anything to `data.table` converter, and all manipulation functions in `collapse`, if passed `data.table`'s, return valid `data.table`'s, allowing for subsequent reference operations (`:=`).\n\nIt's added functionality includes a rich set of [Fast Statistical Functions](https://sebkrantz.github.io/collapse/reference/fast-statistical-functions.html) supporting vectorized (grouped, weighted) statistical operations on matrix-like objects. These are integrated with fast [data manipulation functions](https://sebkrantz.github.io/collapse/reference/fast-data-manipulation.html) in a way that also [more complex statistical expressions can be vectorized across groups](https://andrewghazi.github.io/posts/collapse_is_sick/sick.html). It also adds [flexible time series functions and classes](https://sebkrantz.github.io/collapse/reference/time-series-panel-series.html) supporting irregular series and panels, [(panel-)data transformations](https://sebkrantz.github.io/collapse/reference/data-transformations.html), [vectorized hash-joins](https://sebkrantz.github.io/collapse/reference/join.html), [fast aggregation and recast pivots](https://sebkrantz.github.io/collapse/reference/pivot.html), [(internal) support for variable labels](https://sebkrantz.github.io/collapse/reference/small-helpers.html), [powerful descriptive tools](https://sebkrantz.github.io/collapse/reference/summary-statistics.html), [memory efficient programming tools](https://sebkrantz.github.io/collapse/reference/efficient-programming.html), and [recursive tools for heterogeneous nested data](https://sebkrantz.github.io/collapse/reference/list-processing.html).\n\nIt is [highly and interactively configurable](https://sebkrantz.github.io/collapse/reference/collapse-options.html). A navigable [internal documentation/overview](https://sebkrantz.github.io/collapse/reference/collapse-documentation.html) facilitates its use.\n\n## Overview\n\nThe easiest way to load `collapse` and `data.table` together is via the [`fastverse` package](https://github.com/fastverse/fastverse):\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fastverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n-- Attaching packages ------------------------------------------------------------------------------- fastverse 0.3.3 --\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nv data.table 1.15.4     v kit        0.0.19\nv magrittr   2.0.3      v collapse   2.0.16\n```\n\n\n:::\n:::\n\n\nThis demonstrates `collapse`'s *deep integration* with `data.table`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmtcarsDT <- qDT(mtcars)                # This creates a valid data.table (no deep copy)\nmtcarsDT[, new := mean(mpg), by = cyl] # Proof: no warning here\n```\n:::\n\n\nThere are many reasons to use `collapse`, e.g., to compute advanced statistics very fast:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fast tidyverse-like functions: one of the ways to code with collapse\nmtcDTagg <- mtcarsDT |> \n  fgroup_by(cyl, vs, am) |> \n  fsummarise(mpg_wtd_median = fmedian(mpg, wt),             # Weighted median\n             mpg_wtd_p90 = fnth(mpg, 0.9, wt, ties = \"q8\"), # Weighted 90% quantile type 8\n             mpg_wtd_mode = fmode(mpg, wt, ties = \"max\"),   # Weighted maximum mode \n             mpg_range = fmax(mpg) %-=% fmin(mpg),          # Range: vectorized and memory efficient   \n             lm_mpg_carb = fsum(mpg, W(carb)) %/=% fsum(W(carb)^2)) # coef(lm(mpg ~ carb)): vectorized\n# Note: for increased parsimony, can appreviate fgroup_by -> gby, fsummarise -> smr\nmtcDTagg[, new2 := 1][1:3] # Still a data.table\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     cyl    vs    am mpg_wtd_median mpg_wtd_p90 mpg_wtd_mode mpg_range lm_mpg_carb  new2\n   <num> <num> <num>          <num>       <num>        <num>     <num>       <num> <num>\n1:     4     0     1           26.0    26.00000         26.0       0.0         NaN     1\n2:     4     1     0           22.8    24.40000         24.4       2.9         2.1     1\n3:     4     1     1           30.4    33.48809         30.4      12.5        -1.7     1\n```\n\n\n:::\n:::\n\n\nOr simply, convenience functions like `collap()` for fast multi-type aggregation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# World Development Dataset (see ?wlddev)\nhead(wlddev, 3) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      country iso3c       date year decade     region     income  OECD PCGDP LIFEEX GINI       ODA     POP\n1 Afghanistan   AFG 1961-01-01 1960   1960 South Asia Low income FALSE    NA 32.446   NA 116769997 8996973\n2 Afghanistan   AFG 1962-01-01 1961   1960 South Asia Low income FALSE    NA 32.962   NA 232080002 9169410\n3 Afghanistan   AFG 1963-01-01 1962   1960 South Asia Low income FALSE    NA 33.471   NA 112839996 9351441\n```\n\n\n:::\n\n```{.r .cell-code}\n# Population weighted mean for numeric and mode for non-numeric columns (multithreaded and \n# vectorized across groups and columns, the default in statistical functions is na.rm = TRUE)\nwlddev |> collap(~ year + income, fmean, fmode, w = ~ POP, nthreads = 4) |> ss(1:3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        country iso3c       date year decade                region              income  OECD      PCGDP   LIFEEX GINI\n1 United States   USA 1961-01-01 1960   1960 Europe & Central Asia         High income  TRUE 12768.7126 68.59372   NA\n2      Ethiopia   ETH 1961-01-01 1960   1960    Sub-Saharan Africa          Low income FALSE   658.4778 38.33382   NA\n3         India   IND 1961-01-01 1960   1960            South Asia Lower middle income FALSE   500.7932 45.26707   NA\n         ODA       POP\n1  911825661 749495030\n2  160457982 147355735\n3 3278899549 927990163\n```\n\n\n:::\n:::\n\n\nWe can also use the low-level API for statistical programming:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Grouped mean\nfmean(mtcars$mpg, mtcars$g) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       3        4        5 \n16.10667 24.53333 21.38000 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Grouping object from multiple columns\ng <- GRP(mtcars, c(\"cyl\", \"vs\", \"am\"))\nfmean(mtcars$mpg, g)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   4.0.1    4.1.0    4.1.1    6.0.1    6.1.0    8.0.0    8.0.1 \n26.00000 22.90000 28.37143 20.56667 19.12500 15.05000 15.40000 \n```\n\n\n:::\n\n```{.r .cell-code}\nvars <- c(\"carb\", \"hp\", \"qsec\") # columns to aggregate\n# Aggreagting: weighted mean: vectorized across groups and columns \nadd_vars(g$groups, # Grouping columns\n  fmean(get_vars(mtcars, vars), g, \n        w = mtcars$wt, use.g.names = FALSE)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  cyl vs am     carb        hp     qsec\n1   4  0  1 2.000000  91.00000 16.70000\n2   4  1  0 1.720045  83.60420 21.04028\n3   4  1  1 1.416115  82.11819 18.75509\n4   6  0  1 4.670296 131.78463 16.33306\n5   6  1  0 2.522685 115.32202 19.21275\n6   8  0  0 3.186582 196.74988 17.20449\n7   8  0  1 6.118694 301.60682 14.55297\n```\n\n\n:::\n\n```{.r .cell-code}\n# Let's aggregate a matrix \nm <- matrix(abs(rnorm(32^2)), 32)\nm |> fmean(g) |> t() |> fmean(g) |> t()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          4.0.1     4.1.0     4.1.1     6.0.1     6.1.0     8.0.0     8.0.1\n4.0.1 1.4521108 0.3523314 0.8342670 0.9171383 0.9653782 0.9972716 0.9588307\n4.1.0 0.4862770 0.8524147 0.7069511 1.0736184 0.7940877 0.7172582 0.6543751\n4.1.1 0.8559884 0.8533788 0.8341950 0.8516854 0.6340604 0.8739776 0.7811358\n6.0.1 0.9444262 0.7027453 1.0463235 0.7361824 0.8646207 0.9863881 0.7091550\n6.1.0 0.9136786 0.8365409 0.8170907 0.8222345 0.9893137 0.9412397 0.9012829\n8.0.0 0.8671352 0.8113418 0.6135990 0.6826202 0.8601678 0.7693314 0.8069385\n8.0.1 0.4695412 1.0580121 0.8191335 0.9231220 0.6918469 0.8509011 1.2230739\n```\n\n\n:::\n\n```{.r .cell-code}\n# Normalizing the columns, by reference\nfsum(m, TRA = \"/\", set = TRUE)\nfsum(m) # Check\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n```\n\n\n:::\n\n```{.r .cell-code}\n# Multiply the rows with a vector (by reference)\nsetop(m, \"*\", mtcars$mpg, rowwise = TRUE)\n# Replace some elements with a number\nsetv(m, 3:40, 5.76) # Could also use a vector to copy from\nwhichv(m, 5.76) # get the indices back...\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40\n```\n\n\n:::\n:::\n\n\nIt is also fairly easy to do more involved data exploration and manipulation:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Groningen Growth and Development Center 10 Sector Database (see ?GGDC10S)\nnamlab(GGDC10S, N = TRUE, Ndistinct = TRUE, class = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Variable     Class    N Ndist                                                 Label\n1     Country character 5027    43                                               Country\n2  Regioncode character 5027     6                                           Region code\n3      Region character 5027     6                                                Region\n4    Variable character 5027     2                                              Variable\n5        Year   numeric 5027    67                                                  Year\n6         AGR   numeric 4364  4353                                          Agriculture \n7         MIN   numeric 4355  4224                                                Mining\n8         MAN   numeric 4355  4353                                         Manufacturing\n9          PU   numeric 4354  4237                                             Utilities\n10        CON   numeric 4355  4339                                          Construction\n11        WRT   numeric 4355  4344                         Trade, restaurants and hotels\n12        TRA   numeric 4355  4334                  Transport, storage and communication\n13       FIRE   numeric 4355  4349 Finance, insurance, real estate and business services\n14        GOV   numeric 3482  3470                                   Government services\n15        OTH   numeric 4248  4238               Community, social and personal services\n16        SUM   numeric 4364  4364                               Summation of sector GDP\n```\n\n\n:::\n\n```{.r .cell-code}\n# Describe total Employment and Value-Added\ndescr(GGDC10S, SUM ~ Variable)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDataset: GGDC10S, 1 Variables, N = 5027\nGrouped by: Variable [2]\n        N   Perc\nEMP  2516  50.05\nVA   2511  49.95\n------------------------------------------------------------------------------------------------------------------------\nSUM (numeric): Summation of sector GDP\nStatistics (N = 4364, 13.19% NAs)\n        N   Perc  Ndist         Mean          SD     Min             Max   Skew    Kurt\nEMP  2225  50.99   2225     36846.87    96318.65  173.88          764200   5.02   30.98\nVA   2139  49.01   2139  43'961639.1  358'350627       0  8.06794210e+09  15.77  289.46\n\nQuantiles\n         1%      5%      10%      25%        50%          75%          90%         95%         99%\nEMP  256.12  599.38  1599.27  3555.62    9593.98      24801.5     66975.01   152402.28    550909.6\nVA        0   25.01   444.54    21302  243186.47  1'396139.11  15'926968.3  104'405351  692'993893\n------------------------------------------------------------------------------------------------------------------------\n```\n\n\n:::\n\n```{.r .cell-code}\n# Compute growth rate (Employment and VA, all sectors)\nGGDC10S_growth <- tfmv(GGDC10S, AGR:SUM, fgrowth, # tfmv = transform variables. Alternatively: fmutate(across(...))\n                       g = list(Country, Variable), t = Year, # Internal grouping and ordering, passed to fgrowth()\n                       apply = FALSE) # apply = FALSE ensures we call fgrowth.data.frame\n\n# Recast the dataset, median growth rate across years, taking along variable labels \nGGDC_med_growth <- pivot(GGDC10S_growth,\n  ids = c(\"Country\", \"Regioncode\", \"Region\"),\n  values = slt(GGDC10S, AGR:SUM, return = \"names\"), # slt = shorthand for fselect()\n  names = list(from = \"Variable\", to = \"Sectorcode\"),\n  labels = list(to = \"Sector\"), \n  FUN = fmedian,  # Fast function = vectorized\n  how = \"recast\"  # Recast (transposition) method\n) |> qDT()\nGGDC_med_growth[1:3]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Country Regioncode             Region Sectorcode       Sector        VA       EMP\n    <char>     <char>             <char>     <fctr>       <fctr>     <num>     <num>\n1:     BWA        SSA Sub-saharan Africa        AGR Agriculture   8.790267 0.8921475\n2:     ETH        SSA Sub-saharan Africa        AGR Agriculture   6.664964 2.5876142\n3:     GHA        SSA Sub-saharan Africa        AGR Agriculture  28.215905 1.4045550\n```\n\n\n:::\n\n```{.r .cell-code}\n# Finally, lets just join this to wlddev, enabling multiple matches (cartesian product)\n# -> on average 61 years x 11 sectors = 671 records per unique (country) match\njoin(wlddev, GGDC_med_growth, on = c(\"iso3c\" = \"Country\"), \n     how = \"inner\", multiple = TRUE) |> ss(1:3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ninner join: wlddev[iso3c] 2379/13176 (18.1%) <61:11> GGDC_med_growth[Country] 429/473 (90.7%)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    country iso3c       date year decade                    region              income  OECD    PCGDP LIFEEX GINI\n1 Argentina   ARG 1961-01-01 1960   1960 Latin America & Caribbean Upper middle income FALSE 5642.765 65.055   NA\n2 Argentina   ARG 1961-01-01 1960   1960 Latin America & Caribbean Upper middle income FALSE 5642.765 65.055   NA\n3 Argentina   ARG 1961-01-01 1960   1960 Latin America & Caribbean Upper middle income FALSE 5642.765 65.055   NA\n        ODA      POP Regioncode        Region Sectorcode        Sector       VA        EMP\n1 219809998 20481779        LAM Latin America        AGR  Agriculture  32.91968 -0.8646301\n2 219809998 20481779        LAM Latin America        MIN        Mining 25.72799  1.5627293\n3 219809998 20481779        LAM Latin America        MAN Manufacturing 26.66754  1.0801500\n```\n\n\n:::\n:::\n\n\n**In summary:** `collapse` provides flexible high-performance statistical and data manipulation tools, which extend and seamlessly integrate with `data.table`. The package follows a similar development philosophy emphasizing API stability, parsimonious syntax, and zero dependencies (apart from `Rcpp`). `data.table` users may wish to employ `collapse` for some of the advanced statistical and manipulation functionality showcased above, but also to efficiently manipulate other data frame-like objects, such as [`sf` data frames](https://sebkrantz.github.io/collapse/articles/collapse_and_sf.html).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}