{
  "hash": "f1acc9504183ed564fe782ee35538f1c",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Comparing `data.table` reshape to `duckdb` and `polars`\"\nauthor: \"Toby Dylan Hocking\"\ndate: \"2024-10-17\"\ncategories: [tips, tutorials, developer, benchmarks]\nimage: \"duckdb.png\"\ndraft: false\nexecute:\n  cache: true\n---\n\n\n\n\nOne element of [the NSF POSE grant for `data.table`](https://rdatatable-community.github.io/The-Raft/posts/2023-10-15-intro_to_grant-toby_hocking/) is to create benchmarks which can inform users about when `data.table` could be more performant than similar software. Two examples of similar software are `duckdb` and `polars`, which each provide in-memory database operations. This post explores the differences in computational requirements, and in functionality, for data reshaping operations.\n\n# Terminology and functions in R, `data.table`, and SQL\n\nData reshaping means changing the shape of the data, in order to get it into a more appropriate format, for learning/plotting/etc. In R we use the terms \"wide\" (many columns, few rows) and \"long\" (few columns, many rows) to describe the different data shapes (and these terms come from `?stats::reshape`), whereas in SQL we use the terms \"pivoted\" and \"unpivoted\" to describe these two table types.\n\n| R table type | SQL table type | rows | columns |\n|--------------|----------------|------|---------|\n| long         | unpivoted      | many | few     |\n| wide         | pivoted        | few  | many    |\n\nFor the wide-to-long reshape operation, `data.table` has `melt()` and SQL has `UNPIVOT`; for the long-to-wide reshape operation, `data.table` has `dcast()` and SQL has `PIVOT`.\n\n| Reshape operation | `data.table` function | SQL function |\n|-------------------|-----------------------|--------------|\n| Wide-to-long      | `melt`                | `UNPIVOT`    |\n| Long-to-wide      | `dcast`               | `PIVOT`      |\n\n# Wide-to-long operations\n\nWe begin with a discussion of wide-to-long reshape operations, also known as unpivot in SQL.\n\n## Wide-to-long data reshape (unpivot) using `data.table::melt`\n\nWide-to-long reshape is often necessary before plotting. It is perhaps best explained using a simple example. Here we consider the iris data, which has four numeric columns:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\n(iris.wide <- data.table(iris))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n            <num>       <num>        <num>       <num>    <fctr>\n  1:          5.1         3.5          1.4         0.2    setosa\n  2:          4.9         3.0          1.4         0.2    setosa\n  3:          4.7         3.2          1.3         0.2    setosa\n  4:          4.6         3.1          1.5         0.2    setosa\n  5:          5.0         3.6          1.4         0.2    setosa\n ---                                                            \n146:          6.7         3.0          5.2         2.3 virginica\n147:          6.3         2.5          5.0         1.9 virginica\n148:          6.5         3.0          5.2         2.0 virginica\n149:          6.2         3.4          5.4         2.3 virginica\n150:          5.9         3.0          5.1         1.8 virginica\n```\n\n\n:::\n:::\n\n\n\n\nWhat if we wanted to make a facetted histogram of the numeric iris data columns, with one panel/facet for each column? With ggplots we would use `geom_histogram(aes(numeric_variable))`, where `numeric_variable` would be the column name of a data table containing all of the numbers that we want to show in the histogram. To construct that table, we would have to first reshape to \"long\" (or unpivoted) format. To easily understand what the reshape operation does, we show a subset of the data (first and last rows) below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(two.iris.wide <- iris.wide[c(1,.N)])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n          <num>       <num>        <num>       <num>    <fctr>\n1:          5.1         3.5          1.4         0.2    setosa\n2:          5.9         3.0          5.1         1.8 virginica\n```\n\n\n:::\n:::\n\n\n\n\nNote the table above has 8 numbers, arranged into a table of 2 rows and 4 columns. To reshape these data to \"long\" (or unpivoted) format, we can use `data.table::melt`, as in the code below.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmelt(two.iris.wide, measure.vars=measure(part, dim, sep=\".\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Species   part    dim value\n      <fctr> <char> <char> <num>\n1:    setosa  Sepal Length   5.1\n2: virginica  Sepal Length   5.9\n3:    setosa  Sepal  Width   3.5\n4: virginica  Sepal  Width   3.0\n5:    setosa  Petal Length   1.4\n6: virginica  Petal Length   5.1\n7:    setosa  Petal  Width   0.2\n8: virginica  Petal  Width   1.8\n```\n\n\n:::\n:::\n\n\n\n\nNote the table above has the same 8 numbers, but arranged into 1 column in a table with 8 rows, which is the desired input for ggplots. Also note that the reshaped column names (`Petal.Length`, `Sepal.Width`, etc) each consist of two components, which become two different columns in the output: `part` (`Sepal` or `Petal`) and `dim` (`Length` or `Width`). In the code above, we used `sep=\".\"` to specify that we want to split all of the iris column names using a dot, and then reshape all of the columns whose names split into the max number of items. The corresponding column names of the output are specified as the arguments of `measure()`, and for more info about this functionality, please read [its man page](https://rdatatable.gitlab.io/data.table/reference/measure.html).\n\nBelow we do the same reshape with the full iris data set, this time using a regular expression (instead of the `sep` argument used above),\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(iris.long <- melt(iris.wide, measure.vars=measure(part, dim, pattern=\"(.*)[.](.*)\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Species   part    dim value\n        <fctr> <char> <char> <num>\n  1:    setosa  Sepal Length   5.1\n  2:    setosa  Sepal Length   4.9\n  3:    setosa  Sepal Length   4.7\n  4:    setosa  Sepal Length   4.6\n  5:    setosa  Sepal Length   5.0\n ---                              \n596: virginica  Petal  Width   2.3\n597: virginica  Petal  Width   1.9\n598: virginica  Petal  Width   2.0\n599: virginica  Petal  Width   2.3\n600: virginica  Petal  Width   1.8\n```\n\n\n:::\n:::\n\n\n\n\nIn the code above, the `pattern` argument is a Perl-compatible regular expression, and columns that match the pattern will be reshaped. The pattern must contain the same number of capture groups (parentheses) as the number of other arguments to melt (part and dim), which are used for output column names. After reshaping, we plot the data in a histogram:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot()+\n  geom_histogram(aes(\n    value),\n    bins=50,\n    data=iris.long)+\n  facet_grid(part ~ dim, labeller=label_both)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/dcast-hist-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can see in the plot above that there is a top strip for each `dim` and a right strip for each `part`, and each facet/panel contains a histogram of the corresponding subset of data.\n\n## Wide-to-long reshape via unpivot in `polars`\n\n![We're all friends here.](seal_polar.png){width=\"40%\"}\n\n`polars` is an implementation of data frames in Rust, with bindings in R and Python. In `polars`, the wide-to-long data reshape operation is documented on the [man page for unpivot](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.unpivot.html#polars.DataFrame.unpivot), which explains that we must specify `index` and/or `on` (no support for separator, nor regex). In our case, we use the code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(iris.long.polars <- polars::as_polars_df(iris)$unpivot(\n  index=\"Species\",\n  on=c(\"Sepal.Length\",\"Petal.Length\",\"Sepal.Width\",\"Petal.Width\"),\n  variable_name=\"part.dim\",\n  value_name=\"cm\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nshape: (600, 3)\n┌───────────┬──────────────┬─────┐\n│ Species   ┆ part.dim     ┆ cm  │\n│ ---       ┆ ---          ┆ --- │\n│ cat       ┆ str          ┆ f64 │\n╞═══════════╪══════════════╪═════╡\n│ setosa    ┆ Sepal.Length ┆ 5.1 │\n│ setosa    ┆ Sepal.Length ┆ 4.9 │\n│ setosa    ┆ Sepal.Length ┆ 4.7 │\n│ setosa    ┆ Sepal.Length ┆ 4.6 │\n│ setosa    ┆ Sepal.Length ┆ 5.0 │\n│ …         ┆ …            ┆ …   │\n│ virginica ┆ Petal.Width  ┆ 2.3 │\n│ virginica ┆ Petal.Width  ┆ 1.9 │\n│ virginica ┆ Petal.Width  ┆ 2.0 │\n│ virginica ┆ Petal.Width  ┆ 2.3 │\n│ virginica ┆ Petal.Width  ┆ 1.8 │\n└───────────┴──────────────┴─────┘\n```\n\n\n:::\n:::\n\n\n\n\nThe output above is analogous to the result from `data.table::melt`, but with one column named `part.dim` instead of the two columns named `part` and `dim`, because `polars` does not support splitting the reshaped column names into more than one output column. So with `polars`, if we wanted separate `part` and `dim` columns, we would have to specify that in a separate step, after the reshape. Or we could just use `facet_wrap` instead of `facet_grid`, as in the code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot()+\n  geom_histogram(aes(\n    cm),\n    bins=50,\n    data=iris.long.polars)+\n  facet_wrap(. ~ part.dim, labeller=label_both)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/polars-hist-1.png){width=672}\n:::\n:::\n\n\n\n\nWe can see in the plot above that there is a facet for each of the variables, but only one `part.dim` strip for each, instead of two strips (`part` and `dim`), as was the case for the previous plot.\n\n### Wide-to-long reshape via UNPIVOT in `duckdb`\n\n![(Image generated with Adobe Firefly.)](seal_duck.jpg){width=\"40%\"}\n\n`duckdb` is a column-oriented database implemented in C++, with an R package that supports a DBI-compliant SQL interface. That means that we use R functions like `DBI::dbGetQuery` to get results, just like we would with any other database (Postgres, MySQL, etc). This is documented in the [`duckdb` R API](https://duckdb.org/docs/api/r.html) docs, which explain how to create a database connection, and then copy data from R to the database, as in the code below,\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncon <- DBI::dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\nDBI::dbWriteTable(con, \"iris_wide\", iris)\n```\n:::\n\n\n\n\nThe [`duckdb` unpivot man page](https://duckdb.org/docs/sql/statements/unpivot.html) explains how to do wide-to-long reshape operations, which requires specifying names of columns to reshape (no support for separator, nor regex). In our case, we use the code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris.long.duckdb <- DBI::dbGetQuery(con, '\nUNPIVOT iris_wide\nON \"Sepal.Length\", \"Petal.Length\", \"Sepal.Width\", \"Petal.Width\" \nINTO NAME part_dim \nVALUE cm')\nstr(iris.long.duckdb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t600 obs. of  3 variables:\n $ Species : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ part_dim: chr  \"Sepal.Length\" \"Petal.Length\" \"Sepal.Width\" \"Petal.Width\" ...\n $ cm      : num  5.1 1.4 3.5 0.2 4.9 1.4 3 0.2 4.7 1.3 ...\n```\n\n\n:::\n:::\n\n\n\n\nAbove we use `str` to show a brief summary of the structure of the output, which is a `data.frame` with 600 rows. With `duckdb`, the output has one column named `part_dim` (dots in column names are not allowed so we use an underscore here instead), because it does not support splitting the reshaped column names into more than one output column. So with `duckdb`, if we wanted separate `part` and `dim` columns, we would have to specify that in a separate step, after the reshape.\n\n## Creating `part` and `dim` columns\n\nBoth `polars` and `duckdb` are not capable of producing the separate `part` and `dim` columns during the reshape operation, but we can always do it as a post-processing step. One way to do that, by specifying a separator, would be via `data.table::tstrsplit`, as in the code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata.table(iris.long.duckdb)[\n, c(\"part\",\"dim\") := tstrsplit(part_dim, split=\"[.]\")\n][]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Species     part_dim    cm   part    dim\n        <fctr>       <char> <num> <char> <char>\n  1:    setosa Sepal.Length   5.1  Sepal Length\n  2:    setosa Petal.Length   1.4  Petal Length\n  3:    setosa  Sepal.Width   3.5  Sepal  Width\n  4:    setosa  Petal.Width   0.2  Petal  Width\n  5:    setosa Sepal.Length   4.9  Sepal Length\n ---                                           \n596: virginica  Petal.Width   2.3  Petal  Width\n597: virginica Sepal.Length   5.9  Sepal Length\n598: virginica Petal.Length   5.1  Petal Length\n599: virginica  Sepal.Width   3.0  Sepal  Width\n600: virginica  Petal.Width   1.8  Petal  Width\n```\n\n\n:::\n:::\n\n\n\n\nThe code above first converts to `data.table`, then uses the square brackets to assign new columns. Inside the square brackets, there is a walrus assignment:\n\n-   `,` comma because there is no first argument (no subset, use all rows)\n-   `c(\"part\",\"dim\")` is the left side of the walrus `:=` assignment, which specifies the new column names to create.\n-   on the right side of the walrus, the result of `tstrsplit(part_dim,   split=\"[.]\")` is used as the value to assign to the new columns (`part_dim` is the column to split, and `\"[.]\"` is the regex to use for splitting).\n-   Since `tstrsplit` returns a list of two character vectors, there will be two new columns.\n\nFinally after the walrus square brackets, we use another empty square brackets `[]` to enable printing (there is no printing immediately after assigning new columns using the walrus operator).\n\nAnother way of doing that, by specifying a regex, would be via `nc::capture_first_df` (recently given the `data.table` [Seal of Approval](https://rdatatable-community.github.io/The-Raft/posts/2024-08-01-seal_of_approval-nc/)), as in the code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnc::capture_first_df(iris.long.duckdb, part_dim=list(\n  part=\".*\",\n  \"[.]\",\n  dim=\".*\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Species     part_dim    cm   part    dim\n        <fctr>       <char> <num> <char> <char>\n  1:    setosa Sepal.Length   5.1  Sepal Length\n  2:    setosa Petal.Length   1.4  Petal Length\n  3:    setosa  Sepal.Width   3.5  Sepal  Width\n  4:    setosa  Petal.Width   0.2  Petal  Width\n  5:    setosa Sepal.Length   4.9  Sepal Length\n ---                                           \n596: virginica  Petal.Width   2.3  Petal  Width\n597: virginica Sepal.Length   5.9  Sepal Length\n598: virginica Petal.Length   5.1  Petal Length\n599: virginica  Sepal.Width   3.0  Sepal  Width\n600: virginica  Petal.Width   1.8  Petal  Width\n```\n\n\n:::\n:::\n\n\n\n\nThe code above specifies:\n\n-   `capture_first_df`, a function for applying capturing regex to columns of a data frame;\n-   `iris.long.duckdb` is the input data frame, in which there is the `part_dim` column to split;\n-   `part=\".*\", \"[.]\", dim=\".*\"` makes the capturing regex; R argument names are used to define the new column names, based on the text captured in the corresponding regex (`\".*\"` means zero or more non-newline characters).\n\nBoth results above are data tables with extra cols `part` and `dim`. For visualization, these data tables could be used with either `facet_grid` or `facet_wrap`, similar to the examples above.\n\n## Reshape into multiple columns\n\nAnother kind of wide-to-long reshape involves reshaping into multiple columns. For example, in the iris data, we may wonder whether sepals are larger than petals (in terms of both length and width). To answer that question, we could make a scatterplot of `y=Sepal` versus `x=Petal`, with a facet/panel for each dimension (`Length` and `Width`). In the ggplot system, we would need to compute a data table with columns `Sepal`, `Petal`, and `dim`, and we can do that by specifying the `value.name` keyword to `measure()`, as in the code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(iris.long.parts <- melt(iris.wide, measure.vars=measure(value.name, dim, sep=\".\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Species    dim Sepal Petal\n        <fctr> <char> <num> <num>\n  1:    setosa Length   5.1   1.4\n  2:    setosa Length   4.9   1.4\n  3:    setosa Length   4.7   1.3\n  4:    setosa Length   4.6   1.5\n  5:    setosa Length   5.0   1.4\n ---                             \n296: virginica  Width   3.0   2.3\n297: virginica  Width   2.5   1.9\n298: virginica  Width   3.0   2.0\n299: virginica  Width   3.4   2.3\n300: virginica  Width   3.0   1.8\n```\n\n\n:::\n:::\n\n\n\n\nAgain, the `measure()` function in the code above operates by splitting the input column names using `sep`, which results in two groups (`Sepal.Width` split into `Sepal` and `Width`, etc) for each of the measured columns. The `value.name` keyword indicates that each unique value in the first group (`Sepal` and `Petal`) should be used as the name of an output column. This functionality can be very convenient for some data reshaping tasks, but it is neither supported in `polars`, nor in `duckdb`. Going back to our original motivating problem, we can make the scatterplot using the code below,\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot()+\n  theme_bw()+\n  geom_abline(slope=1, intercept=0, color=\"grey\")+\n  geom_point(aes(\n    Petal, Sepal),\n    data=iris.long.parts)+\n  facet_grid(. ~ dim, labeller=label_both)+\n  coord_equal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/iris-scatter-1.png){width=672}\n:::\n:::\n\n\n\n\nFrom the plot above, we see that all of the data points (black) are above the y=x line (grey), so we can conclude that sepals are indeed larger than petals, in terms of both length and width.\n\n## Wide-to-long performance comparison\n\nWe may also wonder which data reshaping functions work fastest for large data. To answer that question, we will use `atime`, which is an R package that allows us to see how much time/memory is required for computations in R, as a function of data size `N`. In the `setup` argument of the code below, we repeat the iris data for a certain number of rows `N`. The code in the other arguments is run for the time/memory measurement, and is very similar to the code presented in previous sections. One difference is that for `data.table` we use `id.vars` instead of `measure()`, to more closely match the arguments provided to the other unpivot functions (for a more fair comparison).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseconds.limit <- 0.1\nunpivot.res <- atime::atime(\n  N=2^seq(1,50),\n  setup={\n    (row.id.vec <- 1+(seq(0,N-1) %% nrow(iris)))\n    N.df <- iris[row.id.vec,]\n    N.dt <- data.table(N.df)\n    polars_df <- polars::as_polars_df(N.df)\n    duckdb::dbWriteTable(con, \"iris_table\", N.df, overwrite=TRUE)\n  },\n  seconds.limit=seconds.limit,\n  \"duckdb\\nUNPIVOT\"=DBI::dbGetQuery(con, 'UNPIVOT iris_table ON \"Sepal.Length\", \"Petal.Length\", \"Sepal.Width\", \"Petal.Width\" INTO NAME part_dim VALUE cm'),\n  \"polars\\nunpivot\"=polars_df$unpivot(index=\"Species\", value_name=\"cm\"),\n  \"data.table\\nmelt\"=melt(N.dt, id.vars=\"Species\", value.name=\"cm\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\nWarning: Some expressions had a GC in every iteration; so filtering is\ndisabled.\n```\n\n\n:::\n\n```{.r .cell-code}\nunpivot.refs <- atime::references_best(unpivot.res)\nunpivot.pred <- predict(unpivot.refs)\nplot(unpivot.pred)+coord_cartesian(xlim=c(1e1,1e7))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required namespace: directlabels\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in ggplot2::scale_x_log10(\"N\", breaks = meas[,\n10^seq(ceiling(min(log10(N))), : log-10 transformation introduced infinite\nvalues.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/atime-unpivot-1.png){width=672}\n:::\n:::\n\n\n\n\nIn the plot above, the computation time in seconds is plotted as a function of `N`, the number of input rows to reshape. The horizontal reference line is drawn at 0.1 seconds, and the `N` highlighted corresponds to the throughput given that time limit. When we compare the `N` values shown for the different methods, we see that `data.table` is comparable to `polars` (within 2x), and both are much faster than `duckdb` (about 10x).\n\nAbove there are several confounding factors in the comparison, most notably that data must be copied to `duckdb` and `polars` before and after processing. In contrast, `data.table` provides `setDT` and `setDF` functions, which can convert to/from data tables, without copying. So when data originates in R, or needs to come back to R, we should include the copy time for a more fair comparison. Below we run that comparison:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseconds.limit <- 0.1\nunpivot.copy.res <- atime::atime(\n  N=2^seq(1,50),\n  setup={\n    (row.id.vec <- 1+(seq(0,N-1) %% nrow(iris)))\n    N.df <- iris[row.id.vec,]\n  },\n  seconds.limit=seconds.limit,\n  \"duckdb\\ncopy+UNPIVOT\"={\n    duckdb::dbWriteTable(con, \"iris_table\", N.df, overwrite=TRUE)\n    DBI::dbGetQuery(con, 'UNPIVOT iris_table ON \"Sepal.Length\", \"Petal.Length\", \"Sepal.Width\", \"Petal.Width\" INTO NAME part_dim VALUE cm')\n  },\n  \"polars\\ncopy+unpivot\"={\n    polars_df <- polars::as_polars_df(N.df)\n    polars_unpivot <- polars_df$unpivot(index=\"Species\", value_name=\"cm\")\n    as.data.frame(polars_unpivot)\n  },\n  \"data.table\\nset+melt\"=setDF(melt(setDT(N.df), id.vars=\"Species\", value.name=\"cm\")))\nunpivot.copy.refs <- atime::references_best(unpivot.copy.res)\nunpivot.copy.pred <- predict(unpivot.copy.refs)\nplot(unpivot.copy.pred)+coord_cartesian(xlim=c(1e1,1e7))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in ggplot2::scale_x_log10(\"N\", breaks = meas[,\n10^seq(ceiling(min(log10(N))), : log-10 transformation introduced infinite\nvalues.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/atime-unpivot-copy-1.png){width=672}\n:::\n:::\n\n\n\n\nThe result above shows that `data.table` is most efficient in terms of computation time. In this comparison, `data.table` is clearly faster than `polars` (about 10x), and much faster than `duckdb` (about 100x).\n\n## Wide-to-long summary of functionality\n\n![Wide to long.](wide_long.jpeg){width=\"40%\"}\n\nIn this section, we showed that `data.table` provides an efficient and feature-rich implementation of wide-to-long data reshaping.\n\n-   `measure()` allows specification of columns to reshape using either a separator or a regular expression pattern. In contrast, `duckdb` nor `polars` require specifying input column names (no support for separator, nor regex), and output column post-processing, which is less convenient.\n\n-   The `value.name` keyword can be used to reshape into multiple output columns, which is required for some kinds of reshape operations (no way to do that in `duckdb`/`polars`).\n\n-   `setDT` and `setDF` can be used to avoid un-necessary copies with `data.table`. In contrast, `duckdb`/`polars` require copies to/from regular R memory, which can add significant time/memory requirements.\n\n-   `data.table` was fastest and most memory efficient in the comparisons we examined (both with and without consideration of copying).\n\nThe table below summarizes support for different features in each software package (dash - means no support).\n\n| how to specify        | `data.table`     | `polars`        | `duckdb`    |\n|-----------------------|------------------|-----------------|-------------|\n| function              | `melt`           | `unpivot`       | `UNPIVOT`   |\n| reshape cols          | `measure.vars`   | `on`            | `ON`        |\n| other cols            | `id.vars`        | `index`         | \\-          |\n| output name (data)    | `value.name`     | `value_name`    | `VALUE`     |\n| output name (columns) | `variable.name`  | `variable_name` | `INTO NAME` |\n| separator             | `sep`            | \\-              | \\-          |\n| regex                 | `pattern`        | \\-              | \\-          |\n| multiple outputs      | `value.name`     | \\-              | \\-          |\n| avoid copies          | `setDT`, `setDF` | \\-              | \\-          |\n\n# Long-to-wide operations\n\nAnother kind of reshape operation starts with a long table (many rows, few cols), and creates a wide table (many cols, few rows). I frequently use this operation when comparing results of machine learning algorithms (computing mean/SD over folds, p-values, etc). For examples of those use cases, please read my blog about [Visualizing prediction error](https://tdhock.github.io/blog/2024/viz-pred-err/).\n\n## Long-to-wide data reshape using `data.table::dcast`\n\nHere we continue with the iris data example. We will present three different reshape operations involving the iris data. The code below adds a column `flower` which contains the row number.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris.wide[, flower := .I][]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     Sepal.Length Sepal.Width Petal.Length Petal.Width   Species flower\n            <num>       <num>        <num>       <num>    <fctr>  <int>\n  1:          5.1         3.5          1.4         0.2    setosa      1\n  2:          4.9         3.0          1.4         0.2    setosa      2\n  3:          4.7         3.2          1.3         0.2    setosa      3\n  4:          4.6         3.1          1.5         0.2    setosa      4\n  5:          5.0         3.6          1.4         0.2    setosa      5\n ---                                                                   \n146:          6.7         3.0          5.2         2.3 virginica    146\n147:          6.3         2.5          5.0         1.9 virginica    147\n148:          6.5         3.0          5.2         2.0 virginica    148\n149:          6.2         3.4          5.4         2.3 virginica    149\n150:          5.9         3.0          5.1         1.8 virginica    150\n```\n\n\n:::\n:::\n\n\n\n\nThen we do a wide-to-long reshape using the code below (same as previous section),\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(iris.long.i <- melt(iris.wide, measure.vars=measure(part, dim, sep=\".\")))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Species flower   part    dim value\n        <fctr>  <int> <char> <char> <num>\n  1:    setosa      1  Sepal Length   5.1\n  2:    setosa      2  Sepal Length   4.9\n  3:    setosa      3  Sepal Length   4.7\n  4:    setosa      4  Sepal Length   4.6\n  5:    setosa      5  Sepal Length   5.0\n ---                                     \n596: virginica    146  Petal  Width   2.3\n597: virginica    147  Petal  Width   1.9\n598: virginica    148  Petal  Width   2.0\n599: virginica    149  Petal  Width   2.3\n600: virginica    150  Petal  Width   1.8\n```\n\n\n:::\n:::\n\n\n\n\nThe table above has an additional column for `flower`, which we use in the code below on the left side of the formula (used to define output rows), along with `part + dim` on the right side of the formula (used to define output columns). The code below can therefore be used to reshape the data back into their original wide format:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndcast(# wide reshape 1\n  data=iris.long.i,\n  formula=flower + Species ~ part + dim,\n  sep=\".\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <flower, Species>\n     flower   Species Petal.Length Petal.Width Sepal.Length Sepal.Width\n      <int>    <fctr>        <num>       <num>        <num>       <num>\n  1:      1    setosa          1.4         0.2          5.1         3.5\n  2:      2    setosa          1.4         0.2          4.9         3.0\n  3:      3    setosa          1.3         0.2          4.7         3.2\n  4:      4    setosa          1.5         0.2          4.6         3.1\n  5:      5    setosa          1.4         0.2          5.0         3.6\n ---                                                                   \n146:    146 virginica          5.2         2.3          6.7         3.0\n147:    147 virginica          5.0         1.9          6.3         2.5\n148:    148 virginica          5.2         2.0          6.5         3.0\n149:    149 virginica          5.4         2.3          6.2         3.4\n150:    150 virginica          5.1         1.8          5.9         3.0\n```\n\n\n:::\n:::\n\n\n\n\nWe can see that the result above is almost the same as the original iris data (but with the columns in a different order). Another kind of reshape involves computing an aggregation function, such as `mean`. Note in the code below that `.` on the right side of the formula indicates a single output column.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndcast(# wide reshape 2\n  data=iris.long.i,\n  formula=Species + part + dim ~ .,\n  fun.aggregate=mean,\n  sep=\".\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <Species, part, dim>\n       Species   part    dim     .\n        <fctr> <char> <char> <num>\n 1:     setosa  Petal Length 1.462\n 2:     setosa  Petal  Width 0.246\n 3:     setosa  Sepal Length 5.006\n 4:     setosa  Sepal  Width 3.428\n 5: versicolor  Petal Length 4.260\n 6: versicolor  Petal  Width 1.326\n 7: versicolor  Sepal Length 5.936\n 8: versicolor  Sepal  Width 2.770\n 9:  virginica  Petal Length 5.552\n10:  virginica  Petal  Width 2.026\n11:  virginica  Sepal Length 6.588\n12:  virginica  Sepal  Width 2.974\n```\n\n\n:::\n:::\n\n\n\n\nThe output above has a row for every unique combination of `Species`, `part`, and `dim`, and a column (`.`)\\` for the mean of the corresponding data. The more complex reshape below involves multiple aggregations, and multiple value variables.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptions(width=100)\ndcast(# wide reshape 3\n  data=iris.long.parts,\n  formula=dim ~ Species,\n  fun.aggregate=list(mean,sd),\n  value.var=c(\"Sepal\",\"Petal\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKey: <dim>\n      dim Sepal_mean_setosa Sepal_mean_versicolor Sepal_mean_virginica Petal_mean_setosa\n   <char>             <num>                 <num>                <num>             <num>\n1: Length             5.006                 5.936                6.588             1.462\n2:  Width             3.428                 2.770                2.974             0.246\n   Petal_mean_versicolor Petal_mean_virginica Sepal_sd_setosa Sepal_sd_versicolor\n                   <num>                <num>           <num>               <num>\n1:                 4.260                5.552       0.3524897           0.5161711\n2:                 1.326                2.026       0.3790644           0.3137983\n   Sepal_sd_virginica Petal_sd_setosa Petal_sd_versicolor Petal_sd_virginica\n                <num>           <num>               <num>              <num>\n1:          0.6358796       0.1736640           0.4699110          0.5518947\n2:          0.3224966       0.1053856           0.1977527          0.2746501\n```\n\n\n:::\n:::\n\n\n\n\nThe output above includes two rows, and a column for every unique combination of `value.var` (`Sepal` or `Petal`), of `fun.aggregate` (`mean` or `sd`), and of `Species` (`setosa`, `versicolor`, `virginica`).\n\n## Long-to-wide reshape in `polars`\n\n`polars` supports long-to-wide reshape via [the `pivot` method](https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.pivot.html), as in the code below.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(polars.wide <- polars::as_polars_df(\n  iris.long.i\n)$pivot(# wide reshape 1\n  on=c(\"part\",\"dim\"),\n  index=c(\"flower\",\"Species\"),\n  values=\"value\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nshape: (150, 6)\n┌────────┬───────────┬───────────────────┬───────────────────┬──────────────────┬──────────────────┐\n│ flower ┆ Species   ┆ {\"Sepal\",\"Length\" ┆ {\"Sepal\",\"Width\"} ┆ {\"Petal\",\"Length ┆ {\"Petal\",\"Width\" │\n│ ---    ┆ ---       ┆ }                 ┆ ---               ┆ \"}               ┆ }                │\n│ i32    ┆ cat       ┆ ---               ┆ f64               ┆ ---              ┆ ---              │\n│        ┆           ┆ f64               ┆                   ┆ f64              ┆ f64              │\n╞════════╪═══════════╪═══════════════════╪═══════════════════╪══════════════════╪══════════════════╡\n│ 1      ┆ setosa    ┆ 5.1               ┆ 3.5               ┆ 1.4              ┆ 0.2              │\n│ 2      ┆ setosa    ┆ 4.9               ┆ 3.0               ┆ 1.4              ┆ 0.2              │\n│ 3      ┆ setosa    ┆ 4.7               ┆ 3.2               ┆ 1.3              ┆ 0.2              │\n│ 4      ┆ setosa    ┆ 4.6               ┆ 3.1               ┆ 1.5              ┆ 0.2              │\n│ 5      ┆ setosa    ┆ 5.0               ┆ 3.6               ┆ 1.4              ┆ 0.2              │\n│ …      ┆ …         ┆ …                 ┆ …                 ┆ …                ┆ …                │\n│ 146    ┆ virginica ┆ 6.7               ┆ 3.0               ┆ 5.2              ┆ 2.3              │\n│ 147    ┆ virginica ┆ 6.3               ┆ 2.5               ┆ 5.0              ┆ 1.9              │\n│ 148    ┆ virginica ┆ 6.5               ┆ 3.0               ┆ 5.2              ┆ 2.0              │\n│ 149    ┆ virginica ┆ 6.2               ┆ 3.4               ┆ 5.4              ┆ 2.3              │\n│ 150    ┆ virginica ┆ 5.9               ┆ 3.0               ┆ 5.1              ┆ 1.8              │\n└────────┴───────────┴───────────────────┴───────────────────┴──────────────────┴──────────────────┘\n```\n\n\n:::\n\n```{.r .cell-code}\nnames(polars.wide)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"flower\"                 \"Species\"                \"{\\\"Sepal\\\",\\\"Length\\\"}\"\n[4] \"{\\\"Sepal\\\",\\\"Width\\\"}\"  \"{\\\"Petal\\\",\\\"Length\\\"}\" \"{\\\"Petal\\\",\\\"Width\\\"}\" \n```\n\n\n:::\n:::\n\n\n\n\nThe output above is consistent with the results from `data.table::dcast`, and the original iris data, although the names are unusual (with curly braces and double quotes). The next reshape example below shows that we need to create a dummy variable to use as the `on` argument.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolars::as_polars_df(\n  iris.long.i[, dummy := \".\"]\n)$pivot(# wide reshape 2\n  on=\"dummy\", # have to create dummy var for on.\n  index=c(\"Species\",\"part\",\"dim\"),\n  values=\"value\",\n  aggregate_function=\"mean\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nshape: (12, 4)\n┌────────────┬───────┬────────┬───────┐\n│ Species    ┆ part  ┆ dim    ┆ .     │\n│ ---        ┆ ---   ┆ ---    ┆ ---   │\n│ cat        ┆ str   ┆ str    ┆ f64   │\n╞════════════╪═══════╪════════╪═══════╡\n│ setosa     ┆ Sepal ┆ Length ┆ 5.006 │\n│ versicolor ┆ Sepal ┆ Length ┆ 5.936 │\n│ virginica  ┆ Sepal ┆ Length ┆ 6.588 │\n│ setosa     ┆ Sepal ┆ Width  ┆ 3.428 │\n│ versicolor ┆ Sepal ┆ Width  ┆ 2.77  │\n│ …          ┆ …     ┆ …      ┆ …     │\n│ versicolor ┆ Petal ┆ Length ┆ 4.26  │\n│ virginica  ┆ Petal ┆ Length ┆ 5.552 │\n│ setosa     ┆ Petal ┆ Width  ┆ 0.246 │\n│ versicolor ┆ Petal ┆ Width  ┆ 1.326 │\n│ virginica  ┆ Petal ┆ Width  ┆ 2.026 │\n└────────────┴───────┴────────┴───────┘\n```\n\n\n:::\n:::\n\n\n\n\nThe output above is consistent with the results from `data.table::dcast`. Currently `polars` only supports a single aggregation function, so we can not calculate both `mean` and `sd` at the same time, but we can at least do the `mean` for multiple `values` in the code below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npolars::as_polars_df(\n  iris.long.parts\n)$pivot(# wide reshape 3\n  on=\"Species\",\n  index=\"dim\",\n  values=c(\"Sepal\",\"Petal\"),\n  aggregate_function=\"mean\")#multiple agg not supported.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nshape: (2, 7)\n┌────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┬──────────────┐\n│ dim    ┆ Sepal_setosa ┆ Sepal_versic ┆ Sepal_virgin ┆ Petal_setosa ┆ Petal_versic ┆ Petal_virgin │\n│ ---    ┆ ---          ┆ olor         ┆ ica          ┆ ---          ┆ olor         ┆ ica          │\n│ str    ┆ f64          ┆ ---          ┆ ---          ┆ f64          ┆ ---          ┆ ---          │\n│        ┆              ┆ f64          ┆ f64          ┆              ┆ f64          ┆ f64          │\n╞════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╪══════════════╡\n│ Length ┆ 5.006        ┆ 5.936        ┆ 6.588        ┆ 1.462        ┆ 4.26         ┆ 5.552        │\n│ Width  ┆ 3.428        ┆ 2.77         ┆ 2.974        ┆ 0.246        ┆ 1.326        ┆ 2.026        │\n└────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┴──────────────┘\n```\n\n\n:::\n:::\n\n\n\n\nAbove we see the result only has 6 columns (for `mean`), whereas the analogous result from `data.table::dcast` above had 12 columns (with additionally the `sd`).\n\n## Long-to-wide reshape in `duckdb`\n\n`duckdb` supports long-to-wide reshape via [the SQL `PIVOT` command](https://duckdb.org/docs/sql/statements/pivot.html), which can be used to recover the original iris data via the command below:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nduckdb::dbWriteTable(con, \"iris_long_i\", iris.long.i, overwrite=TRUE)\niris.wide.again.duckdb <- DBI::dbGetQuery(# wide reshape 1\n  con, '\nPIVOT iris_long_i \nON part,dim \nUSING sum(value) \nGROUP BY flower,Species \nORDER BY flower')\nstr(iris.wide.again.duckdb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t150 obs. of  6 variables:\n $ flower      : int  1 2 3 4 5 6 7 8 9 10 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ Petal_Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal_Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Sepal_Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal_Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n```\n\n\n:::\n:::\n\n\n\n\nWe can see that the result above is consistent with the previous sections. The code below uses `mean` as an aggregation function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDBI::dbGetQuery(# wide reshape 2\n  con, '\nPIVOT iris_long_i \nUSING mean(value) \nAS \".\" \nGROUP BY Species,part,dim')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Species  part    dim     .\n1  versicolor Petal Length 4.260\n2  versicolor Petal  Width 1.326\n3      setosa Sepal Length 5.006\n4      setosa Sepal  Width 3.428\n5   virginica Petal Length 5.552\n6   virginica Petal  Width 2.026\n7  versicolor Sepal Length 5.936\n8   virginica Sepal Length 6.588\n9  versicolor Sepal  Width 2.770\n10  virginica Sepal  Width 2.974\n11     setosa Petal Length 1.462\n12     setosa Petal  Width 0.246\n```\n\n\n:::\n:::\n\n\n\n\nThe result above is consistent with previous results. Finally, we can do multiple aggregations via the code below, which requires enumerating each combination of aggregation function and input column to aggregate.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nduckdb::dbWriteTable(con, \"iris_long_parts\", iris.long.parts, overwrite=TRUE)\nDBI::dbGetQuery(# wide reshape 3\n  con, '\nPIVOT iris_long_parts \nON Species \nUSING \n mean(Sepal) AS Sepal_mean, \n stddev(Sepal) AS Sepal_sd, \n mean(Petal) AS Petal_mean, \n stddev(Petal) AS Petal_sd \nGROUP BY dim')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     dim setosa_Sepal_mean setosa_Sepal_sd setosa_Petal_mean setosa_Petal_sd versicolor_Sepal_mean\n1 Length             5.006       0.3524897             1.462       0.1736640                 5.936\n2  Width             3.428       0.3790644             0.246       0.1053856                 2.770\n  versicolor_Sepal_sd versicolor_Petal_mean versicolor_Petal_sd virginica_Sepal_mean\n1           0.5161711                 4.260           0.4699110                6.588\n2           0.3137983                 1.326           0.1977527                2.974\n  virginica_Sepal_sd virginica_Petal_mean virginica_Petal_sd\n1          0.6358796                5.552          0.5518947\n2          0.3224966                2.026          0.2746501\n```\n\n\n:::\n:::\n\n\n\n\nThe result above is consistent with the result from `data.table::dcast`. Because all combinations of aggregation/columns must be enumerated, the `duckdb` code is a bit more repetitive than the corresponding `data.table` code (which is more convenient).\n\n## Long-to-wide performance comparison\n\nBelow we conduct an `atime` benchmark to measure the computation time of the reshape operation (without controlling for the copy operation).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseconds.limit <- 0.1\npivot.res <- atime::atime(\n  N=2^seq(1,50),\n  setup={\n    (row.id.vec <- 1+(seq(0,N-1) %% nrow(iris.long.i)))\n    N.dt <- iris.long.i[row.id.vec]\n    N.df <- data.frame(N.dt)\n    N_polars <- polars::as_polars_df(N.df)\n    duckdb::dbWriteTable(con, \"iris_long_i\", N.df, overwrite=TRUE)\n  },\n  seconds.limit=seconds.limit,\n  \"duckdb\\nPIVOT\"=DBI::dbGetQuery(con, 'PIVOT iris_long_i USING mean(value) AS \".\" GROUP BY Species,part,dim'),\n  \"polars\\npivot\"=N_polars$pivot(on=\"dummy\", index=c(\"Species\",\"part\",\"dim\"), values=\"value\", aggregate_function=\"mean\"),\n  \"data.table\\ndcast\"=dcast(N.dt, Species + part + dim ~ ., mean))\npivot.refs <- atime::references_best(pivot.res)\npivot.pred <- predict(pivot.refs)\nplot(pivot.pred)+coord_cartesian(xlim=c(1e1,1e7))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in ggplot2::scale_x_log10(\"N\", breaks = meas[, 10^seq(ceiling(min(log10(N))), : log-10\ntransformation introduced infinite values.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/atime-pivot-1.png){width=672}\n:::\n:::\n\n\n\n\nThe result above shows that `data.table::dcast` is about as fast as the others (bottom facet), although `duckdb` is slightly faster, and `polars` is slightly slower (less than 2x). Below we run a more complex benchmark which also measures computation time for the copy operation (in addition to the reshape).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nseconds.limit <- 0.1\npivot.copy.res <- atime::atime(\n  N=2^seq(1,50),\n  setup={\n    (row.id.vec <- 1+(seq(0,N-1) %% nrow(iris.long.i)))\n    N.df <- data.frame(iris.long.i[row.id.vec])\n  },\n  seconds.limit=seconds.limit,\n  \"duckdb\\ncopy+PIVOT\"={\n    duckdb::dbWriteTable(con, \"iris_long_i\", N.df, overwrite=TRUE)\n    DBI::dbGetQuery(con, 'PIVOT iris_long_i USING mean(value) AS \".\" GROUP BY Species,part,dim')\n  },\n  \"polars\\ncopy+pivot\"={\n    polars_pivot <- polars::as_polars_df(\n      N.df\n    )$pivot(# wide reshape 2\n      on=\"dummy\", # have to create dummy var for on.\n      index=c(\"Species\",\"part\",\"dim\"),\n      values=\"value\",\n      aggregate_function=\"mean\")\n    as.data.frame(polars_pivot)\n  },\n  \"data.table\\nset+dcast\"=setDF(dcast(setDT(N.df), Species + part + dim ~ ., mean)))\npivot.copy.refs <- atime::references_best(pivot.copy.res)\npivot.copy.pred <- predict(pivot.copy.refs)\nplot(pivot.copy.pred)+coord_cartesian(xlim=c(1e1,1e7))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in ggplot2::scale_x_log10(\"N\", breaks = meas[, 10^seq(ceiling(min(log10(N))), : log-10\ntransformation introduced infinite values.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/atime-pivot-copy-1.png){width=672}\n:::\n:::\n\n\n\n\nThe result above shows that `data.table` is quite a bit faster than the others (5x or more).\n\n## Summary of long-to-wide reshaping\n\nIn this section, we showed that `data.table` provides an efficient and feature-rich implementation of long-to-wide data reshaping. \\* The formula interface allows specifying a dot (`.`) which is a convenient way to specify output of only one row/column. In contrast, `polars` requires creating a dummy variable to do that. \\* The `fun.aggregate` argument may be a list of functions, each of which will be used on each of the `value.var` (a convenient way of specifying all combinations). In contrast, `duckdb` requires specifying each combination separately (more tedious/error-prone), and `polars` only supports one aggregation function (not a list).\n\n| how to specify | `data.table`     | `polars`             | `duckdb`               |\n|------------------|------------------|------------------|-------------------|\n| function       | `dcast`          | `pivot`              | `PIVOT`                |\n| rows           | LHS of formula   | `index`              | `GROUP BY`             |\n| columns        | RHS of formula   | `on`                 | `ON`                   |\n| no columns     | dot `.`          | dummy variable       | omit `ON`              |\n| values         | `value.var`      | `values`             | `USING`                |\n| aggregation    | `aggregate.fun`  | `aggregate_function` | `USING`                |\n| multiple agg.  | all combinations | one function         | specified combinations |\n\n# Conclusion\n\nWe have compared the reshaping functions in `data.table` to `duckdb` and `polars`. Although all three provide similar functionality for basic operations, we observed that `data.table` has several advantages for advanced/complex/efficient operations (reshaping columns which match a regex/separator, reshaping into multiple columns, avoiding copies, multiple aggregation). We also observed that the speed of `data.table` functions is comparable, if not faster, than the other packages.\n\n## Attribution\n\nParts of this blog post were copied from [my more extensive comparison blog](https://tdhock.github.io/blog/2024/collapse-reshape/).\n\n## Session info\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.2 (2024-10-31)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sequoia 15.1.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Los_Angeles\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] ggplot2_3.5.1     data.table_1.16.2\n\nloaded via a namespace (and not attached):\n [1] gtable_0.3.6           jsonlite_1.8.9         dplyr_1.1.4            compiler_4.4.2        \n [5] tidyselect_1.2.1       directlabels_2024.1.21 scales_1.3.0           yaml_2.3.10           \n [9] fastmap_1.2.0          lattice_0.22-6         R6_2.5.1               labeling_0.4.3        \n[13] generics_0.1.3         knitr_1.49             htmlwidgets_1.6.4      tibble_3.2.1          \n[17] polars_0.21.0          munsell_0.5.1          atime_2024.11.29       DBI_1.2.3             \n[21] pillar_1.9.0           rlang_1.1.4            utf8_1.2.4             xfun_0.49             \n[25] quadprog_1.5-8         cli_3.6.3              withr_3.0.2            magrittr_2.0.3        \n[29] digest_0.6.37          grid_4.4.2             rstudioapi_0.17.1      nc_2024.9.20          \n[33] lifecycle_1.0.4        vctrs_0.6.5            bench_1.1.3            evaluate_1.0.1        \n[37] glue_1.8.0             farver_2.1.2           duckdb_1.1.3           codetools_0.2-20      \n[41] profmem_0.6.0          fansi_1.0.6            colorspace_2.1-1       rmarkdown_2.29        \n[45] tools_4.4.2            pkgconfig_2.0.3        htmltools_0.5.8.1     \n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}